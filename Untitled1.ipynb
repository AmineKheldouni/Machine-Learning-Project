{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rappel des paramĂ¨tres\n",
      "Nombre de donnĂŠes gĂŠnĂŠrĂŠes :  100\n",
      "Nombre de dimensions des donnĂŠes gĂŠnĂŠrĂŠes :  2\n",
      "Nombre d'annotateurs :  5\n",
      "ModĂ¨le :  Bernoulli\n",
      "\n",
      "GĂŠnĂŠration des donnĂŠes\n",
      "Apprentissage ... \n",
      "\n",
      "ITERATION NÂ° 1\n",
      " ... \n",
      "\n",
      "valeur EM\n",
      "4.72824186941\n",
      "W TROUVE !\n",
      "[[ 1.]\n",
      " [ 1.]]\n",
      "ITERATION NÂ° 2\n",
      " ... \n",
      "\n",
      "valeur EM\n",
      "11.5781961908\n",
      "W TROUVE !\n",
      "[[ nan]\n",
      " [ nan]]\n",
      "ITERATION NÂ° 3\n",
      " ... \n",
      "\n",
      "valeur EM\n",
      "nan\n",
      "W TROUVE !\n",
      "[[ nan]\n",
      " [ nan]]\n",
      "valeur de w\n",
      "[[ nan]\n",
      " [ nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:171: RuntimeWarning: divide by zero encountered in true_divide\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py:1776: RuntimeWarning: invalid value encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqNBFRELE/wN3snbzjhdA4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f481483e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apprentissage terminĂŠ ! \n",
      "\n",
      "Score en Train :  0.5\n",
      "\n",
      "Score en Test :  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:368: RuntimeWarning: invalid value encountered in greater\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:127: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apprentissage\n",
      "ITERATION NÂ° 1\n",
      " ... \n",
      "\n",
      "valeur EM\n",
      "0.252987172829\n",
      "W TROUVE !\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "ITERATION NÂ° 2\n",
      " ... \n",
      "\n",
      "valeur EM\n",
      "94.7526790002\n",
      "W TROUVE !\n",
      "[[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "ITERATION NÂ° 3\n",
      " ... \n",
      "\n",
      "valeur EM\n",
      "nan\n",
      "W TROUVE !\n",
      "[[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "valeur de w\n",
      "[[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:171: RuntimeWarning: overflow encountered in exp\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:171: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIgFChS4iEiD+D1T5d8PiRn4VAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f48158b5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performances sur les donnĂŠes d'entrainement : \n",
      "Score en Train :  0.764065335753\n",
      "\n",
      "Performances sur les donnĂŠes de test : \n",
      "Score en Test :  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:377: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "# Modules importĂŠs\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tools import *\n",
    "from scipy.optimize import minimize\n",
    "from random import gauss\n",
    "\n",
    "#Bloc gĂŠnĂŠration de donnĂŠes artificielles de dimension 2\n",
    "\n",
    "def gen_arti(centerx=1,centery=1,sigma=0.1,nbex=1000,data_type=0,epsilon=0.02):\n",
    "    \"\"\" Generateur de donnees,\n",
    "        :param centerx: centre des gaussiennes\n",
    "        :param centery:\n",
    "        :param sigma: des gaussiennes\n",
    "        :param nbex: nombre d'exemples\n",
    "        :param data_type: 0: melange 2 gaussiennes, 1: melange 4 gaussiennes, 2:echequier\n",
    "        :param epsilon: bruit dans les donnees\n",
    "        :return: data matrice 2d des donnnes,y etiquette des donnnees\n",
    "    \"\"\"\n",
    "    if data_type==0:\n",
    "        #melange de 2 gaussiennes\n",
    "        xpos=np.random.multivariate_normal([centerx,centerx],np.diag([sigma,sigma]),int(nbex//2))\n",
    "        xneg=np.random.multivariate_normal([-centerx,-centerx],np.diag([sigma,sigma]),int(nbex//2))\n",
    "        data=np.vstack((xpos,xneg))\n",
    "        y=np.hstack((np.ones(nbex//2),-np.ones(nbex//2)))\n",
    "    if data_type==1:\n",
    "        #melange de 4 gaussiennes\n",
    "        xpos=np.vstack((np.random.multivariate_normal([centerx,centerx],np.diag([sigma,sigma]),int(nbex//4)),np.random.multivariate_normal([-centerx,-centerx],np.diag([sigma,sigma]),int(nbex/4))))\n",
    "        xneg=np.vstack((np.random.multivariate_normal([-centerx,centerx],np.diag([sigma,sigma]),int(nbex//4)),np.random.multivariate_normal([centerx,-centerx],np.diag([sigma,sigma]),int(nbex/4))))\n",
    "        data=np.vstack((xpos,xneg))\n",
    "        y=np.hstack((np.ones(nbex//2),-np.ones(int(nbex//2))))\n",
    "\n",
    "    if data_type==2:\n",
    "        #echiquier\n",
    "        data=np.reshape(np.random.uniform(-4,4,2*nbex),(nbex,2))\n",
    "        y=np.ceil(data[:,0])+np.ceil(data[:,1])\n",
    "        y=2*(y % 2)-1\n",
    "    # un peu de bruit\n",
    "    data[:,0]+=np.random.normal(0,epsilon,nbex)\n",
    "    data[:,1]+=np.random.normal(0,epsilon,nbex)\n",
    "    # on mĂŠlange les donnĂŠes\n",
    "    idx = np.random.permutation((range(y.size)))\n",
    "    data=data[idx,:]\n",
    "    y=y[idx]\n",
    "    return data,y\n",
    "\n",
    "def plot_data(data,labels=None):\n",
    "    \"\"\"\n",
    "    Affiche des donnees 2D\n",
    "    :param data: matrice des donnees 2d\n",
    "    :param labels: vecteur des labels (discrets)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8,8))\n",
    "    cols,marks = [\"red\", \"blue\",\"green\", \"orange\", \"black\", \"cyan\"],[\".\",\"+\",\"*\",\"o\",\"x\",\"^\"]\n",
    "    if labels is None:\n",
    "        plt.scatter(data[:,0],data[:,1],marker=\"x\", linewidth=3.0)\n",
    "        return\n",
    "    for i,l in enumerate(sorted(list(set(labels.flatten())))):\n",
    "        plt.scatter(data[labels==l,0],data[labels==l,1],c=cols[i],marker=marks[i], linewidth=3.0)\n",
    "\n",
    "def plot_frontiere(data,f,step=20):\n",
    "    \"\"\" Trace un graphe de la frontiere de decision de f\n",
    "    :param data: donnees\n",
    "    :param f: fonction de decision\n",
    "    :param step: pas de la grille\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    grid,x,y=make_grid(data=data,step=step)\n",
    "    plt.contourf(x,y,f(grid).reshape(x.shape),256)\n",
    "\n",
    "def make_grid(data=None,xmin=-5,xmax=5,ymin=-5,ymax=5,step=20):\n",
    "    \"\"\" Cree une grille sous forme de matrice 2d de la liste des points\n",
    "    :param data: pour calcluler les bornes du graphe\n",
    "    :param xmin: si pas data, alors bornes du graphe\n",
    "    :param xmax:\n",
    "    :param ymin:\n",
    "    :param ymax:\n",
    "    :param step: pas de la grille\n",
    "    :return: une matrice 2d contenant les points de la grille\n",
    "    \"\"\"\n",
    "    if data is not None:\n",
    "        xmax, xmin, ymax, ymin = np.max(data[:,0]),  np.min(data[:,0]), np.max(data[:,1]), np.min(data[:,1])\n",
    "    x, y =np.meshgrid(np.arange(xmin,xmax,(xmax-xmin)*1./step), np.arange(ymin,ymax,(ymax-ymin)*1./step))\n",
    "    grid=np.c_[x.ravel(),y.ravel()]\n",
    "    return grid, x, y\n",
    "\n",
    "#autre modĂ¨le\n",
    "\n",
    "#qualite annoteur\n",
    "\n",
    "qualite_annoteur=[(0.9,0.1),(0.9,0.1),(0.9,0.1),(0.9,0.1)]\n",
    "\n",
    "def modifie_label(label,qualite_annoteur):\n",
    "    (alpha,beta)=qualite_annoteur\n",
    "    res=-1 #label initili\n",
    "    if label==1:\n",
    "        #on simule avec proba alpha\n",
    "        valeur_proba=np.random.uniform(0,1)\n",
    "        if(valeur_proba>alpha):\n",
    "            res=0\n",
    "        else:\n",
    "            res=1\n",
    "    if label==0:\n",
    "        valeur_proba=np.random.uniform(0,1)\n",
    "        if(valeur_proba>beta):\n",
    "            res=1\n",
    "        else:\n",
    "            res=0\n",
    "    return res\n",
    "\n",
    "def generation_Bernouilli(N,T,qualite_annotateur_Bernoulli,noise_truth):\n",
    "    \"\"\"retourne en xtrain les donnĂŠes de dimension 2, en ytrain les annotations, en ztrain les vrais labels\n",
    "    avec pour qualite_annotateurs une liste contenant les probabilitĂŠs de succĂ¨s de chaque annotateur\n",
    "    noise_truth est le bruit de l'attribution des vrais labels gaussiens sur les donnĂŠes\"\"\"\n",
    "    xtrain,ztrain = gen_arti(nbex=N,data_type=0,epsilon=noise_truth) #vrai labels non bruitĂŠs\n",
    "    ztrain=(ztrain+1)/2\n",
    "    ytrain=np.zeros((N,T)) #changement des labels\n",
    "    for t in range(T):\n",
    "        annote=lambda x:modifie_label(x,qualite_annotateur_Bernoulli[t])\n",
    "        annote=np.vectorize(annote)\n",
    "        ytrain[:,t]=annote(ztrain)\n",
    "    return xtrain,ytrain,ztrain\n",
    "\n",
    "def sigmoide(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "sigmoide = np.vectorize(sigmoide)\n",
    "\n",
    "def calcule_ai(alpha, Y):\n",
    "    T = Y.shape[0]\n",
    "    res=1\n",
    "    ai = np.prod(np.multiply(alpha**Y, (1-alpha)**(1-Y)), axis = 1).reshape((T,1))\n",
    "    return ai\n",
    "    # for t in range(T):\n",
    "    #     res = res*(alpha[0,t]**(Y[t]))*((1-alpha[0,t])**(1-Y[t]))\n",
    "    # return res\n",
    "\n",
    "def calcule_bi(beta, Y):\n",
    "    T=Y.shape[0]\n",
    "    res=1\n",
    "    return np.prod(np.multiply(beta**(1-Y), (1-beta)**(Y)), axis = 1).reshape((T,1))\n",
    "    # for t in range(T):\n",
    "    #     res=res*(beta[0,t]**(1-yi[t]))*((1-beta[0,t])**(yi[t]))\n",
    "    # return res\n",
    "\n",
    "\n",
    "def gradient_modele_w(X, mu, w, l):\n",
    "    N=np.shape(X)\n",
    "    d=np.shape(w)[0]\n",
    "    #vecteur_grad = np.zeros((d,1))\n",
    "    w=w.reshape((d,1))\n",
    "    vecteur_w_x = sigmoide(np.dot(X,w))\n",
    "    vecteur_addition = -mu+vecteur_w_x+1\n",
    "    Matrice_gradient = np.multiply(vecteur_addition,X)\n",
    "    vecteur_res=np.sum(Matrice_gradient,axis=0)\n",
    "    vecteur_res=vecteur_res.reshape((d,1))\n",
    "    #remplacer vecteur_res-2*w pour avoir ridge regression\n",
    "    return np.ndarray.flatten(vecteur_res)\n",
    "\n",
    "\n",
    "\n",
    "def gradient_modele_amine(X, mu, w, l):\n",
    "    N=np.shape(X)\n",
    "    d=np.shape(w)[0]\n",
    "    #vecteur_grad = np.zeros((d,1))\n",
    "    w=w.reshape((d,1))\n",
    "    vecteur_w_x = sigmoide(np.dot(X,w))\n",
    "    vecteur_carre=vecteur_w_x**(2)\n",
    "    vecteur_addition=np.multiply(np.multiply(1/vecteur_w_x,mu)+np.multiply(1-mu,1/(1-vecteur_w_x)),np.multiply(np.exp(-np.dot(X,w)),vecteur_carre))\n",
    "    Matrice_gradient = np.multiply(vecteur_addition,X)\n",
    "    vecteur_res=np.sum(Matrice_gradient,axis=0)\n",
    "    vecteur_res=vecteur_res.reshape((d,1))\n",
    "    #remplacer vecteur_res-2*w pour avoir ridge regression\n",
    "    return np.ndarray.flatten(vecteur_res)\n",
    "\n",
    "def hessien_modele(X,w,l):\n",
    "    N=X.shape[0]\n",
    "    d = w.shape[0]\n",
    "    vecteur_w_x = sigmoide(np.dot(X,w))\n",
    "    Matrice_Hessienne=np.zeros((d,d))\n",
    "    H = -np.multiply(np.multiply(vecteur_w_x,(1-vecteur_w_x)),X).T.dot(X)\n",
    "    return H\n",
    "    # for i in range(N):\n",
    "    #     xi=X[i,:].reshape((d,1))\n",
    "    #     Matrice_Hessienne -= vecteur_w_x[i,0]*(1-vecteur_w_x[i,0])*np.dot(xi,xi.T)\n",
    "    # return Matrice_Hessienne\n",
    "\n",
    "class LearnCrowd2:\n",
    "    def __init__(self, T, N, d, l=0):\n",
    "        self.alpha = np.zeros((1,T)) # sensitivitĂŠ des annoteur\n",
    "        self.beta = np.zeros((1,T)) #specificitĂŠ\n",
    "        self.w = np.ones((d,1)) # Poids pour le modĂ¨le (indĂŠpendant des annoteur)\n",
    "        self.y_trouve=np.zeros((N,1))\n",
    "        self.lb = l\n",
    "\n",
    "    def likelihood(self, X, Y, alpha, beta, w, vrai_y):\n",
    "        # vrai_y = mu_i\n",
    "\n",
    "        N = X.shape[0]\n",
    "        T = Y.shape[1]\n",
    "\n",
    "        p_i = 1/(1+np.exp(-X.dot(w)))+1.0**(-10)\n",
    "        p_i = p_i.reshape((N,1))\n",
    "        a_i = calcule_ai(alpha, Y)\n",
    "        b_i = calcule_bi(alpha, Y)\n",
    "        pi_ai=np.multiply(p_i+1.0**(-10),a_i)\n",
    "        pi_bi=np.multiply((1-p_i+1.0**(-10)),b_i)\n",
    "        \n",
    "        #log_pi = np.log(p_i)\n",
    "        #log_un_pi = np.log(1+1.0**(-10)-p_i)\n",
    "        vrai_un_yi = (1-vrai_y)\n",
    "\n",
    "        #a1 = np.multiply(a_i, log_pi)\n",
    "        #a1 = np.multiply(a1, vrai_y)\n",
    "        v1=np.multiply(vrai_y,np.log(pi_ai+1.0**(-10)))\n",
    "        v2=np.multiply(vrai_un_yi,np.log(pi_bi+1.0**(-10)))\n",
    "\n",
    "        #b1 = np.multiply(b_i, log_un_pi)\n",
    "        #b1 = np.multiply(b1, vrai_un_yi)\n",
    "\n",
    "        #log_res = np.sum(a1+b1)\n",
    "        log_res=np.sum(v1+v2)\n",
    "\n",
    "        return log_res\n",
    "\n",
    "    def fit(self, X, Y, model=\"Bernoulli\", eps = 10**(-3)):\n",
    "        N = X.shape[0]\n",
    "        d = X.shape[1]\n",
    "        T = Y.shape[1]\n",
    "\n",
    "        #EM Algorithm\n",
    "\n",
    "        #Initialization\n",
    "\n",
    "        alpha=np.ones((1,T))\n",
    "        alphaNew=0.5*np.ones((1,T))\n",
    "        beta=np.ones((1,T))\n",
    "        betaNew=0.5*np.ones((1,T))\n",
    "        #initialisation des mu avec le majority voting\n",
    "        mu_inter=(np.sum(Y,axis=1)/T)\n",
    "\n",
    "        mu = mu_inter.reshape((N,1))\n",
    "        w = np.ones((d,1))\n",
    "\n",
    "        # nombre_iteration = 0\n",
    "        cpt_iter=1\n",
    "        # self.liste_em=[]\n",
    "        # self.norme_gradient=[]\n",
    "        # valeur_EM_before=1\n",
    "        # valeur_EM=1000\n",
    "        liste_valeur_EM=[]\n",
    "        while (np.linalg.norm(alpha-alphaNew)**2 + np.linalg.norm(beta-betaNew)**2 >= eps and (cpt_iter<100)):\n",
    "        #while(abs((valeur_EM-valeur_EM_before)/valeur_EM_before)>=eps and (cpt_iter<=1000)):\n",
    "\n",
    "            print(\"ITERATION NÂ°\",cpt_iter)\n",
    "            print(\" ... \\n\")\n",
    "\n",
    "            alpha = alphaNew\n",
    "            beta= betaNew\n",
    "\n",
    "\n",
    "            valeur_EM = self.likelihood(X,Y,alphaNew,betaNew,w,mu)\n",
    "            liste_valeur_EM.append(valeur_EM)\n",
    "            print(\"valeur EM\")\n",
    "            print(valeur_EM)\n",
    "            # Expectation (E-step)\n",
    "            if(cpt_iter!=0):\n",
    "                    # self.liste_em.append(valeur_EM)\n",
    "                    #on change les valeurs des mu\n",
    "                    pi = sigmoide(np.dot(X,w)) + 1.0**(-10)\n",
    "                    #\n",
    "                    # for i in range(N):\n",
    "                    #     ai = calcule_ai(alphaNew,Y[i,:])\n",
    "                    #     bi = calcule_bi(betaNew,Y[i,:])\n",
    "                    #     pi = p_i[i,0]\n",
    "                    #     mu[i,0] = ai*pi/(ai*pi+bi*(1-pi))\n",
    "                    ai = calcule_ai(alphaNew, Y)\n",
    "                    bi = calcule_bi(betaNew, Y)\n",
    "\n",
    "                    mu = np.multiply(ai, pi) / (ai * pi + bi * (1-pi))\n",
    "\n",
    "\n",
    "            cpt_iter+=1\n",
    "            # Maximization (M-step)\n",
    "            \n",
    "            \n",
    "            #Optimisation de w\n",
    "             # \"Zippage\" de self.w\n",
    "            #autre optimisation\n",
    "            w_inter=w.reshape((d,1))\n",
    "            grad_w=gradient_modele_w(X,mu,w_inter,0)\n",
    "            nombre_iteration=0\n",
    "            while(np.linalg.norm(grad_w)>1.0**(-4) and nombre_iteration<1000):\n",
    "                Hess=hessien_modele(X,w_inter,0)\n",
    "                if(abs(np.linalg.det(Hess))<1.0**(-5)):\n",
    "                    Hess=np.eye(d,d)\n",
    "                direction=-gradient_modele_amine(X,mu,w_inter,1)\n",
    "                direction=direction.reshape((d,1))\n",
    "                w_inter=w_inter-0.005*np.dot(np.linalg.inv(Hess),direction)\n",
    "                grad_w=direction\n",
    "                nombre_iteration+=1\n",
    "                \n",
    "            def BFGSfunc(vect):\n",
    "                #print(\"Vect\",vect)\n",
    "                # print(\"Vraisemblance : \",-self.likelihood(Pt, X, Y, model, vect[0:d].reshape((1,d)), float(vect[d:d+1]), vect[d+1:d+1+T].reshape((1,T)), vect[d+1+T:d+1+T+d*T].reshape((d,T))))\n",
    "                \n",
    "                d=np.shape(vect)[0]\n",
    "                #fuck=vect.reshape((d,1))\n",
    "                \n",
    "                return -self.likelihood(X, Y, alphaNew, betaNew,vect,mu)\n",
    "\n",
    "            def BFGSJac(vect):\n",
    "            \n",
    "                d=np.shape(vect)[0]\n",
    "                #fuck=vect.reshape((d,1))\n",
    "                #print(\"Gradient\",-self.grad_likelihood(Pt, X, Y, model, vect[0:d].reshape((1,d)), float(vect[d:d+1]), vect[d+1:d+1+T].reshape((1,T)), vect[d+1+T:d+1+T+d*T].reshape((d,T))))\n",
    "                \n",
    "                return -gradient_modele_amine(X, mu, vect, l=0)\n",
    "\n",
    "            Teta_init = w\n",
    "            Teta_init=np.ndarray.flatten(w)\n",
    "            \n",
    "            #rappels des tailles de alpha, beta, gamma, w : (1,d), 1, (1,T), (d,T)\n",
    "            #LH.append(BFGSfunc(Teta_init))\n",
    "            #result = minimize(BFGSfunc, Teta_init, method='BFGS', jac = BFGSJac,\\\n",
    "                              #options={'gtol': 1e-10, 'disp': True, 'maxiter': 5000})\n",
    "            #print(result.message)\n",
    "            # print(\"Optimal solution :\")\n",
    "            # print(result.x)\n",
    "\n",
    "            # \"Dézippage\" de Teta solution en self.alpha, self.beta, self.gamma, self.w\n",
    "            # To Update new vectors :\n",
    "\n",
    "            #Teta = result.x\n",
    "            #w=Teta.reshape((d,1))\n",
    "            w=w_inter\n",
    "\n",
    "           \n",
    "            print(\"W TROUVE !\")\n",
    "            print(w)\n",
    "\n",
    "            #calcul de alpha\n",
    "            alpha_inter = np.dot(Y.T, mu) / ((np.sum(mu)) + 1.0**(-10))\n",
    "            alphaNew=alpha_inter.reshape((1,T))\n",
    "            #calcul de beta\n",
    "            mu_inter = 1-mu\n",
    "            y_inter = np.ones((N,T))-Y\n",
    "            beta_inter = np.dot(y_inter.T,mu_inter) / ((np.sum(mu_inter))+1.0**(-10))\n",
    "            betaNew = beta_inter.reshape((1,T))\n",
    "\n",
    "\n",
    "        self.alpha = alphaNew\n",
    "        self.beta = betaNew\n",
    "        self.w = w\n",
    "        print(\"valeur de w\")\n",
    "        print(w)\n",
    "        #\n",
    "        plt.plot([i for i in range(len(liste_valeur_EM))],liste_valeur_EM)\n",
    "        plt.show()\n",
    "        plt.legend(\"variation de l'Em avec les itĂŠrations\")\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        #on prĂŠdit les vrais labels Ă  partir des donnĂŠes X\n",
    "        proba_class_1 = sigmoide(np.dot(X,self.w))\n",
    "        labels_predicted = proba_class_1 > 0.5\n",
    "        #labels_predicted = 2*labels_predicted-1\n",
    "        return labels_predicted.ravel()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def score(self, X, Z):\n",
    "        # On connaĂŽt la vĂŠritĂŠ terrain\n",
    "        return np.mean(self.predict(X)==Z)\n",
    "\n",
    "\n",
    "    def debug(self):\n",
    "        print(\"w : \\n\")\n",
    "        print(self.w)\n",
    "        print(\"alpha : \\n\")\n",
    "        print(self.alpha)\n",
    "        print(\"beta : \\n\")\n",
    "        print(self.beta)\n",
    "\n",
    "def LearnfromtheCrowd2(N,T, d, modele,qualite_annotateurs, generateur,noise_truth=0):\n",
    "    print(\"Rappel des paramĂ¨tres\")\n",
    "    print(\"Nombre de donnĂŠes gĂŠnĂŠrĂŠes : \", N)\n",
    "    print(\"Nombre de dimensions des donnĂŠes gĂŠnĂŠrĂŠes : \", d)\n",
    "    print(\"Nombre d'annotateurs : \", T)\n",
    "    print(\"ModĂ¨le : \", modele)\n",
    "    # print(\"ProbabilitĂŠs de succĂ¨s des annotateurs : \", qualite_annotateurs)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"GĂŠnĂŠration des donnĂŠes\")\n",
    "\n",
    "    xtrain, ytrain,ztrain = generateur(N,T,qualite_annotateurs,noise_truth)\n",
    "    xtest, ytest,ztest = generateur(N,T,qualite_annotateurs,noise_truth)\n",
    "\n",
    "#     print(\"DonnĂŠes d'entrainement\")\n",
    "#     print(\"DonnĂŠes X : \", xtrain)\n",
    "#     print(\"Vrai Labels : \", ztrain)\n",
    "#     print(\"Labels donnĂŠes par les annotateurs Y : \", ytrain)\n",
    "#     print(\"\")\n",
    "    # print(\"ytrain size :\", ytrain.shape)\n",
    "    # print(\"xtrain size :\", xtrain.shape)\n",
    "    # plot_data(xtrain,ztrain)\n",
    "    # plt.title(\"DonnĂŠes et labels de dĂŠpart (gaussiennes bruitĂŠes)\")\n",
    "    # plt.show()\n",
    "    #\n",
    "    # if modele==\"Bernoulli\":\n",
    "    #     plot_data(xtrain,ytrain[:,0])\n",
    "    #     plt.title(\"Annotations d'un labelleur\")\n",
    "    #     plt.show()\n",
    "    #\n",
    "    # print(\"DonnĂŠes de test\")\n",
    "    # '''print(\"DonnĂŠes X : \", xtest)\n",
    "    # print(\"Vrai Labels : \", ztest)\n",
    "    # #print(\"Labels donnĂŠes par les annotateurs Y : \", ytest)\n",
    "    # print(\"\")'''\n",
    "\n",
    "    S = LearnCrowd2(T, N, d)\n",
    "\n",
    "    print(\"Apprentissage ... \\n\")\n",
    "    S.fit(xtrain,ytrain)\n",
    "    print(\"Apprentissage terminĂŠ ! \\n\")\n",
    "\n",
    "    # print(\"Performances sur les donnĂŠes d'entrainement : \")\n",
    "    print(\"Score en Train : \", S.score(xtrain,ztrain))\n",
    "    print(\"\")\n",
    "\n",
    "    #plot_frontiere(xtest,S.predict(xtest),step=50) C'est XTEST ? Pas ZTEST ?\n",
    "    # plot_data(xtrain,S.predict(xtrain))\n",
    "    # plt.title(\"PrĂŠdictions finales sur le Train aprĂ¨s crowdlearning\")\n",
    "    # plt.show()\n",
    "    # print(\"Performances sur les donnĂŠes de test : \")\n",
    "    print(\"Score en Test : \", S.score(xtest,ztest))\n",
    "    # plt.figure()\n",
    "    # #plot_frontiere(xtest,S.predict(xtest),step=50)\n",
    "    # plot_data(xtest,S.predict(xtest))\n",
    "    # plt.title(\"PrĂŠdictions finales sur le Test\")\n",
    "    # plt.show()\n",
    "\n",
    "N = 100 #nb donnĂŠes\n",
    "T = 5 #nb annotateurs\n",
    "d = 2 #nb dimension des donnĂŠes : pas modifiable (gen_arti ne gĂŠnĂ¨re que des donnĂŠes de dimension 2)\n",
    "noise_truth=0.1 #bruit sur l'attribution des vrais labels gaussiens sur les donnĂŠes 2D (on pourrait aussi jouer sur ecart-type gaussienne avec sigma)\n",
    "modele= \"Bernoulli\"\n",
    "qualite_annoteur = [(0.6,0.6)]*T\n",
    "\n",
    "# Test donnĂŠes artificielles :\n",
    "\n",
    "LearnfromtheCrowd2(N,T,d,modele,qualite_annoteur,generation_Bernouilli,noise_truth)\n",
    "\n",
    "\n",
    "# DonnĂŠes rĂŠelles :\n",
    "\n",
    "def load_XZ(filename):\n",
    "    with open(filename,\"r\") as f:\n",
    "        f.readline()\n",
    "        data =[ [x for x in l.split()] for l in f if len(l.split())>2]\n",
    "    X = np.array(data)\n",
    "    return X[:,:X.shape[1]-1], (X[:,X.shape[1]-1].astype(int)+1)/2\n",
    "\n",
    "def load_Y(filename):\n",
    "    with open(filename,\"r\") as f:\n",
    "        f.readline()\n",
    "        data =[ [x for x in l.split()] for l in f if len(l.split())>2]\n",
    "    X = np.array(data)\n",
    "    return X[:,:X.shape[1]-1].astype(int)\n",
    "\n",
    "\n",
    "def genereWithoutMissing(Xmissing,Ymissing):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(Xmissing.shape[0]):\n",
    "        if not '?' in Xmissing[i]:\n",
    "            X.append(Xmissing[i])\n",
    "            Y.append(Ymissing[i])\n",
    "    return np.array(X).astype(int), (np.array(Y).astype(int)+1)/2\n",
    "\n",
    "X,Z = load_XZ('data/dataXZ_Adult.txt')\n",
    "\n",
    "Y = load_Y('data/dataY_Adult.txt')\n",
    "\n",
    "XX,YY = genereWithoutMissing(X,Y)\n",
    "\n",
    "sliceTrain = int(XX.shape[0]*0.8)\n",
    "xtrain, ytrain,ztrain = XX[0:sliceTrain,:], YY[0:sliceTrain,:], Z[0:sliceTrain]\n",
    "xtest, ytest,ztest = XX[sliceTrain+1:,:], YY[sliceTrain+1:,:], Z[sliceTrain+1:]\n",
    "xtrain = np.delete(xtrain,2,axis=1)\n",
    "xtest = np.delete(xtest,2,axis=1)\n",
    "\n",
    "xtrain = (xtrain - np.mean(xtrain)) / np.std(xtrain)\n",
    "xtest = (xtest - np.mean(xtest)) / np.std(xtest)\n",
    "\n",
    "T = YY.shape[1]\n",
    "N = XX.shape[0]\n",
    "d = XX.shape[1]\n",
    "S = LearnCrowd2(T,N,d,0.)\n",
    "\n",
    "print(\"Apprentissage\")\n",
    "S.fit(xtrain,ytrain)\n",
    "\n",
    "print(\"Performances sur les donnĂŠes d'entrainement : \")\n",
    "print(\"Score en Train : \", S.score(xtrain,ztrain))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Performances sur les donnĂŠes de test : \")\n",
    "print(\"Score en Test : \", S.score(xtest,ztest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
