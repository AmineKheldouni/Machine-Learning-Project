{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning from the crowd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Modules importés\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tools import *\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-5-2db244050362>, line 82)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-2db244050362>\"\u001b[0;36m, line \u001b[0;32m82\u001b[0m\n\u001b[0;31m    def predictV2(self, Y):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class LearnCrowd:\n",
    "    def __init__(self, T, N, d):\n",
    "        self.alpha = np.zeros((1,d)) # Poids des dimensions\n",
    "        self.beta = 0\n",
    "        self.w = np.zeros((d,T)) # Poids des labelleurs\n",
    "        self.gamma = np.zeros((1,T))\n",
    "          \n",
    "    def sigma(self, X):\n",
    "        # A FAIRE\n",
    "        return 0\n",
    "    def eta(self, X):\n",
    "        # A FAIRE\n",
    "        return 0\n",
    "    \n",
    "    def likelihoodBernoulli(self, X, Y, gamma, w):\n",
    "        P = np.zeros((X.shape[0],Y.shape[1]))\n",
    "        return P      \n",
    "\n",
    "    def likelihoodGaussian(self, X, Y, gamma, w):\n",
    "        P = np.zeros((X.shape[0],Y.shape[1]))\n",
    "        return P\n",
    "        \n",
    "    def Pz(self, z, X, alpha, beta):\n",
    "        res = 1/(1+np.exp(-alpha.dot(X.T)-beta))\n",
    "        if z == 1:\n",
    "            return res\n",
    "        else:\n",
    "            return 1-res\n",
    "        \n",
    "    def Ptilde(self, X, Y, model, alpha, beta, gamma, w):\n",
    "        Pt = np.zeros((X.shape[0],1))\n",
    "        py = self.model(X,Y, gamma, w) # Taille N,T\n",
    "        pz = self.Pz(1, X, alpha, beta) # Taille : N,1\n",
    "        return np.multiplty(np.prod(py,axis=1),pz) # Taille : N,1\n",
    "    \n",
    "    def likelihood(self, X, Y, model, alpha, beta, gamma, w):\n",
    "        Pt = self.Ptilde(X, Y, model, alpha, beta, gamma, w)\n",
    "        return Pt.T.dot(np.log(Pt))\n",
    "    \n",
    "    def grad_likelihood(self, X, Y, model, alpha, beta, gamma, w):\n",
    "        \"\"\"Returns the partial derivatives of likelihood according to\n",
    "        alpha, beta, gamma and w\"\"\"\n",
    "        tmp_exp = np.exp(-X.dot(alpha.T)-beta)\n",
    "        deltaPt = self.Pz(1,X)-self.Pz(0,X)\n",
    "        grad_lh_alpha = np.sum(deltaPt*np.multiplty(np.multiplty(X,tmp_exp),1/(1+tmp_exp)**2))\n",
    "        grad_lh_beta = np.sum(deltaPt*np.multiplty(tmp_exp,1/(1+tmp_exp)**2))\n",
    "        tmp_exp = np.exp(-X.dot(w)-gamma) # Taille : N,T\n",
    "        grad_etasigma_gamma = tmp_exp/(1+tmp_exp)**2 # Taille : N,T\n",
    "        grad_etasigma_w = np.multiplty(X,tmp_exp)/(1+tmp_exp)**2 # Taille : N,T\n",
    "        if (\"Bernoulli\" in model):\n",
    "            grad_lh_eta = (-1)**Y *(-deltaPt) # Taille : N,T\n",
    "            grad_lh_gamma = np.sum(np.multiply(grad_lh_eta,grad_etasigma_gamma)) \n",
    "            grad_lh_w = np.sum(np.multiply(grad_lh_eta, grad_etasigma,w))\n",
    "        elif (\"Gaussian\" in model):\n",
    "            s = self.sigma(X)\n",
    "            grad_lh_sigma = (Y**2-self.Pz(1,X)*(2*Y-1))/s**3 - 1/s # Taille : N,T\n",
    "            grad_lh_gamma = np.sum(np.multiply(grad_lh_sigma,grad_etasigma_gamma)) \n",
    "            grad_lh_w = np.sum(np.multiply(grad_lh_sigma, grad_etasigma,w))\n",
    "        return np.array([[-grad_lh_alpha, -grad_lh_beta, -grad_lh_gamma, -grad_lh_w]])\n",
    "    \n",
    "    def BFGS_func(self, X, Y, model, alpha, beta, gamma, w):\n",
    "        return [self.likelihood(X, Y, model, alpha, beta, gamma, w), \\\n",
    "                self.grad_likelihood(X, Y, model, alpha, beta, gamma, w)]\n",
    "    \n",
    "    def fit(self, X, Y, model=likelihoodBernoulli, eps = 10**(-6)):\n",
    "        self.alpha = np.zeros((1,d))\n",
    "        self.beta = 0\n",
    "        alphaNew = np.ones((1,d))\n",
    "        betaNew = 1\n",
    "        wNew = np.random.rand(d,T)\n",
    "        gammaNew = np.random.rand(1,T)\n",
    "        while (np.linalg.norm(self.alpha-alphaNew)**2 + (self.beta-betaNew)**2 >= eps):\n",
    "            # Expectation (E-step)\n",
    "            Pt = self.Ptilde(X, Y, Z, model)\n",
    "            # Maximization\n",
    "            lh = - self.likelihood(X, Y, model, alpha, beta, gamma, w)\n",
    "            BFGSfunc = lambda alpha,beta,gamma,w : likelihood(self, X, Y, model, alpha, beta, gamma, w)\n",
    "            BFGSJac = lambda alpha,beta,gamma,w : grad_likelihood(self, X, Y, model, alpha, beta, gamma, w)\n",
    "            result = minimize(BFGSfunc, method='BFGS', jac = BFGSJac, \\\n",
    "                              options={'gtol': 1e-6, 'disp': True, 'maxiter': 1000})\n",
    "            print(result.message)\n",
    "            print(\"Optimal solution :\")\n",
    "            print(result.x)\n",
    "            # Updating new vectors :\n",
    "            alphaNew = result.x[0]\n",
    "            betaNew = result.x[1]\n",
    "            gammaNew = result.x[2]\n",
    "            wNew = result.x[3]\n",
    "            \"\"\"COMMENT ACTUALISE-T-ON SELF.ALPHA ET LES AUTRES SELON LA CONDITION DU WHILE ?\"\"\"\n",
    "        self.alpha = alphaNew\n",
    "        self.beta = betaNew\n",
    "        self.w = wNew\n",
    "        self.gamma = gammaNew\n",
    "    def predict(self, X):\n",
    "        \n",
    "    def predictV2(self, Y):\n",
    "        \n",
    "    def score(self, X, Z):\n",
    "        # On connaît la vérité terrain\n",
    "        return np.sum(predict(X)==Z)\n",
    "    \n",
    "    def get_eps(self):\n",
    "        \n",
    "    def loss(self,data,y):\n",
    "        \n",
    "    def loss_g(self,data,y):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
